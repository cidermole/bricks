# include general Bricks that we will later use below.
Bricks: @<Bricks.cfg>

# Creates the word alignment of a truecased corpus.
# for now also tests PhraseTable.
Experiment: {
  # inherit machine-specific paths, ncpus, ...
  extends: $Bricks.Setups.Hopper

  input:  {
    truecasedSrc: $ibm10k_truecased_train + $sourceLang
    truecasedTrg: $ibm10k_truecased_train + $targetLang

    devSrc: $ibm10k_truecased_dev + $sourceLang
    devRef: $ibm10k_truecased_dev + $targetLang
  }
  output: {
    alignment: $parts.WordAligner0.output.alignment
    phraseTable: $parts.PhraseTable0.output.phraseTable
    reorderingTable: $parts.PhraseTable0.output.reorderingTable
    mosesIni: $parts.MosesIni0.output.mosesIni

    processedItems: $parts.LoopyBrick.output.processedItems

    filteredPhraseTable: $parts.FilterTables0.output.filteredPhraseTable

    tunedMosesIni: $parts.Mert0.output.tunedMosesIni
  }
  
  # language pair
  sourceLang: en
  targetLang: it

  ibm10k_data: "/home/david/mmt/data/training/small/ibm"
  ibm10k_truecased_train: $ibm10k_data + "/train.clean."
  ibm10k_truecased_dev: $ibm10k_data + "/set1.clean."
  ibm10k_truecased_test: $ibm10k_data + "/set2.clean."
  
  parts: {

    # The farthest example of stretching config semantics: describing a series of
    # Bricks, each with a different loop counter $i, to encode experiments with replicated
    # steps, e.g. tune 10 times, grid search over parameter(s), ...
    #
    LoopyBrick: {
      input:  { corpora: [ $_._.input.truecasedSrc, $_._.input.truecasedTrg ] }
      # new, special output list syntax:
      output: { processedItems: [ $parts[$i].output.processed ] }

      # define loop range
      i: [0..$input.corpora.length-1]

      # new, special semantics (parts is a list with one idiomatic entry):
      parts: [{
        # implicit scalar $i

        #extends: $Bricks.blabla
        input: { crp: $_._.input.corpora[$i] }
        output: { processed }
      }]
    }

    LanguageModel0: {
      extends: $Bricks.Phrase.LanguageModelEstimator
      input:  { corpus: $_._.input.truecasedTrg }
      # languageModel: binarized KenLM
      # output: { languageModel }
    }

    WordAligner0: {
      extends: $Bricks.Giza.WordAligner
      input: {
        src: $_._.input.truecasedSrc
        trg: $_._.input.truecasedTrg
      }
      # output: { alignment }
    }

    PhraseTable0: {
      extends: $Bricks.Phrase.PhraseTable
      input: {
        src: $_._.input.truecasedSrc
        trg: $_._.input.truecasedTrg
        alignment: $WordAligner0.output.alignment
      }
      # phraseTable is gzipped
      # output: { phraseTable, reorderingTable }

      reordering: {
        # see http://www.statmt.org/moses/?n=FactoredTraining.BuildReorderingModel
        extends: $Bricks.Phrase.PhraseTable.reordering

        # TODO: moses.ini gets these, but actual LR extraction still makes 8 columns with orient: "msd" here...

        # override orientation
        orient: "mslr"

        # bidirectional: *2, each orientation: *4 feature scores
        numFeatures: 2 * 4
      }
    }

    FilterTables0: {
      extends: $Bricks.Phrase.FilterTables
      # table, filteredPhraseTable, filteredReorderingTable are gzipped
      input: {
        phraseTable: $PhraseTable0.output.phraseTable
        reorderingTable: $PhraseTable0.output.reorderingTable
        src: $_._.input.devSrc
      }
      # output: { filteredPhraseTable, filteredReorderingTable }
    }

    MosesIni0: {
      extends: $Bricks.Phrase.MosesIni
      input: {
        languageModels: [ $LanguageModel0.output.languageModel ]
        phraseTables: [ $PhraseTable0.output.phraseTable ]
        reorderingTables: [ $PhraseTable0.output.reorderingTable ]
      }
      # output: { mosesIni }
    }

    Mert0: {
      extends: $Bricks.Phrase.Mert

      input: {
        mosesIni: $MosesIni0.output.mosesIni
        devSrc: $_._.input.devSrc
        devRef: $_._.input.devRef
      }
      # output: { tunedMosesIni }
    }

  }
}

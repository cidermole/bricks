Bricks: @<Bricks.cfg>

BaselineExperiment: {
  extends: $Setup

  DESCRIPTION: """
    Baseline plain Moses: phrase-based model with lexicalized reordering.
    3-domain MMT data.
  """ + $corporaDescription

  # NOTE: training corpus must be in randomized sentence order
  # for nlinesTrain to work properly.

  # we hence expect train corpus to be ...:
  # * tokenized
  # * truecased (using the most common spelling)
  #     -- really, just want consistent casing with dev and test
  # * cleaned (tokens/sentence limited)

  input: {
    trainSrc: $corpus_truecased_train + $sourceLang
    trainTrg: $corpus_truecased_train + $targetLang

    devSrc: $corpus_truecased_dev + $sourceLang
    devRef: $corpus_truecased_dev + $targetLang

    testSrc: $corpus_truecased_test + $sourceLang
    testRef: $corpus_truecased_test + $targetLang
  }
  output: {
    hyp: $parts.TestMoses0.output.hyp
    score: $parts.Bleu0.output.score
    summary: $parts.Summary0.output.summary
  }

  # language pair
  sourceLang: en
  targetLang: it

  corpora: {
    train: "ep"
    dev: "ep"
    test: "ep"
  }
  variant: "real"  # small|real
  nlinesTrain: ALL  # use the given number of lines for training data

  corpus_data: $MMT_CORPUS_DIR + "/" + $variant
  corpus_truecased_train: $corpus_data + "/" + $corpora.train + "/train.clean."
  corpus_truecased_dev: $corpus_data + "/" + $corpora.dev + "/set1.clean."
  corpus_truecased_test: $corpus_data + "/" + $corpora.test + "/set2.clean."

  corporaDescription: "train: " + $corpora.train + " dev: " + $corpora.dev + " test: " + $corpora.test + " "

  parts: {
    PhraseTable0: {
      extends: $Bricks.Phrase.PhraseTable
      input: {
        src: $LimitTrain0.output.src
        trg: $LimitTrain0.output.trg
        alignment: $WordAligner0.output.alignment
      }
      # phraseTable is gzipped
      # output: { phraseTable, reorderingTable }

      reordering: {
        # see http://www.statmt.org/moses/?n=FactoredTraining.BuildReorderingModel
        extends: $Bricks.Phrase.PhraseTable.reordering

        # override orientation
        orient: "mslr"

        # bidirectional: *2, each orientation: *4 feature scores
        numFeatures: 2 * 4
      }
    }

    DevTables0: {
      extends: $Bricks.Phrase.Post.FilterBinarizeTables
      # table, filteredPhraseTable, filteredReorderingTable are gzipped
      input: {
        phraseTable: $PhraseTable0.output.phraseTable
        reorderingTable: $PhraseTable0.output.reorderingTable
        src: $_._.input.devSrc
      }
      # output: { binaryPhraseTableDir, binaryReorderingTableDir }

      # for various phrase table config (e.g. numFeatures) used in moses.ini
      phraseTableConfig: $PhraseTable0.phraseTableConfig
    }

    TestTables0: {
      extends: $Bricks.Phrase.Post.FilterBinarizeTables
      # table, filteredPhraseTable, filteredReorderingTable are gzipped
      input: {
        phraseTable: $PhraseTable0.output.phraseTable
        reorderingTable: $PhraseTable0.output.reorderingTable
        src: $_._.input.testSrc
      }
      # output: { binaryPhraseTableDir, binaryReorderingTableDir }

      # for various phrase table config (e.g. numFeatures) used in moses.ini
      phraseTableConfig: $PhraseTable0.phraseTableConfig
    }

    TestMosesIni0: {
      extends: $Bricks.Moses.MosesIni
      input: {
        languageModels: [ $LanguageModel0.output.languageModel ]
        phraseTables: []
        reorderingTables: []
        binaryPhraseTables: [ $TestTables0.output.binaryPhraseTableDir ]
        binaryReorderingTables: [ $TestTables0.output.binaryReorderingTableDir ]
      }
      # output: { mosesIni }
    }

    WeightedTestMosesIni0: {
      extends: $Bricks.Moses.WeightedMosesIni
      input: {
        generatedMosesIni: $TestMosesIni0.output.mosesIni
        tunedMosesIni: $Mert0.output.tunedMosesIni
      }
      # output: { weightedMosesIni }
    }

    DevMosesIni0: {
      extends: $Bricks.Moses.MosesIni
      input: {
        languageModels: [ $LanguageModel0.output.languageModel ]
        phraseTables: []
        reorderingTables: []
        binaryPhraseTables: [ $DevTables0.output.binaryPhraseTableDir ]
        binaryReorderingTables: [ $DevTables0.output.binaryReorderingTableDir ]
      }
      # output: { mosesIni }
    }

    Mert0: {
      extends: $Bricks.Moses.Mert

      input: {
        mosesIni: $DevMosesIni0.output.mosesIni
        devSrc: $_._.input.devSrc
        devRef: $_._.input.devRef
      }
      # output: { tunedMosesIni }
    }

    TestMoses0: {
      extends: $Bricks.Moses.Decoder
      input: {
        mosesIni: $WeightedTestMosesIni0.output.weightedMosesIni
        src: $_._.input.testSrc
      }
      # output: { hyp }
    }

    Bleu0: {
      extends: $Bricks.Eval.Bleu
      input: { hyp: $TestMoses0.output.hyp, ref: $_._.input.testRef }
      # output: { score }
    }

    # write a human-readable summary of the experiment and its results.
    Summary0: {
      extends: $Bricks.Summary
      input:  { results: [$Bleu0.output.score] }
      # output: { summary }
    }
  }
}



Experiment: {
  extends: $BaselineExperiment

  DESCRIPTION: """
    Phrase-based model with lexicalized reordering.
    3-domain MMT data. Concatenated training corpus, see below.

    Domain adaptation scenario using mixed training data.

    word alignment: jointly word-aligned full-length training corpora.
    language model: from target side of full-length train corpus
    translation model: from length-limited train corpus

  """ + $corporaDescription

  # must be before input: section
  trainCorpora: ["ep", "ibm"]

  input: {
    trainSources: [$corpora_truecased_train[$i] + $sourceLang | i: [0..$trainCorpora.length-1] ]
    trainTargets: [$corpora_truecased_train[$i] + $targetLang | i: [0..$trainCorpora.length-1] ]

    devSrc: $corpus_truecased_dev + $sourceLang
    devRef: $corpus_truecased_dev + $targetLang

    testSrc: $corpus_truecased_test + $sourceLang
    testRef: $corpus_truecased_test + $targetLang
  }

  output: {
    hyp: $parts.TestMoses0.output.hyp
    score: $parts.Bleu0.output.score
    summary: $parts.Summary0.output.summary

    alignments: $parts.JointWordAligner0.output.alignments
  }

  corpora: {
    train: "ep+ibm10k"  # now only used for corporaDescription
    dev: "ibm"
    test: "ibm"
  }

  corpora_truecased_train: [ $corpus_data + "/" + $trainCorpora[$i] + "/train.clean." | i: [0..$trainCorpora.length-1] ]

  variant: "real"  # small|real

  # we now make this a list!
  # must have same length as trainSources, trainTargets
  nlinesTrain: [ALL, 10000]

  parts: {
    # inherit all parts, except for the override below.
    extends: $MMTBaseline.Experiment.parts

    LimitTrain0: {
      extends: $Bricks.Corpus.BitextConcat

      input:  {
        sources: $LimitTrainCorpora0.output.sources
        targets: $LimitTrainCorpora0.output.targets
      }
      # output: { src, trg }
    }

    LimitTrainCorpora0: {
      input:  {
        sources: $_._.input.trainSources
        targets: $_._.input.trainTargets
      }
      output: {
        sources: [$parts[$i].output.src]
        targets: [$parts[$i].output.trg]
      }

      i: [0..$nlinesTrain.length-1]

      parts: [{
        extends: $Bricks.Corpus.BitextHead

        input:  {
          src: $_._.input.sources[$i]
          trg: $_._.input.targets[$i]
        }
        # output: { src, trg }

        nlines: $nlinesTrain[$i]
      }]
    }

    FullTrgTrain0: {
      extends: $Bricks.Corpus.Concat

      input:  { texts: $_._.input.trainTargets }
      # output: { concat }
    }

    LanguageModel0: {
      extends: $Bricks.LM.LanguageModelEstimator

      input:  { corpus: $FullTrgTrain0.output.concat }
      # languageModel: binarized KenLM
      # output: { languageModel }
    }

    JointWordAligner0: {
      extends: $Bricks.Giza.LimitJointWordAligner

      input:  {
        sources: $_._.input.trainSources
        targets: $_._.input.trainTargets
      }

      # we have to define output list with the correct length.
      # (this cannot currently go into our parent, because list comprehensions are not lazy, but are evaluated at parse time.)
      # output: { alignments: $parts.Split0.output.texts }
      output: {
        alignments: [ $parts.Split0.output.texts[$i] | i: [0..$trainCorpora.length-1] ]
      }

      # from Experiment
      nlinesLimit: $_._.nlinesTrain
    }

    # paste together the limited word alignments.
    #
    WordAligner0: {
      input:  { alignments: $JointWordAligner0.output.alignments }
      output: { alignment: $parts.Concat0.output.concat }

      parts: {
        Concat0: {
          extends: $Bricks.Corpus.Concat
          input:   { texts: $_._.input.alignments }
          # output: { concat }
        }
      }
    }
  }
}

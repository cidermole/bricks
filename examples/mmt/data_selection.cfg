Bricks: @<Bricks.cfg>

# overridden in $Setup / Hopper.cfg only, to simplify testing experiments
MMT_VARIANT: $Setup.MMT_VARIANTS.real

MMTBaseline: @"baseline.cfg"


Experiment: {
  extends: $Setup

  DESCRIPTION: """
    Gather sub-corpus data and prepare for intrinsic eval of training data
    selection.

    Includes randomly splitting off a small part (C_in) and "hiding" the rest
    in a mixed-domain haystack, as inspired by [Cuong & Sima'an 2014].

  """ + $corporaDescription


  # we hence expect train corpus to be ...:
  # * tokenized
  # * truecased (using the most common spelling)
  #     -- really, just want consistent casing with dev and test
  # * cleaned (tokens/sentence limited)

  # language pair
  sourceLang: en
  targetLang: it

  corpora: {
    #train: "ep"
    dev: "ep"
    test: "ep"
  }

  # must be before input: section
  trainCorpora: ["ep", "ibm", "ms"]

  input: {
    trainSources: [$corpora_truecased_train[$i] + $sourceLang | i: [0..$trainCorpora.length-1] ]
    trainTargets: [$corpora_truecased_train[$i] + $targetLang | i: [0..$trainCorpora.length-1] ]

    devSrc: $corpus_truecased_dev + $sourceLang
    devRef: $corpus_truecased_dev + $targetLang

    testSrc: $corpus_truecased_test + $sourceLang
    testRef: $corpus_truecased_test + $targetLang
  }

  output: {
    mlSelections: $parts.ForeachCorpus0.output.mlSelections
    mlScores: $parts.ForeachCorpus0.output.mlScores

    csSelections: $parts.ForeachCorpus0.output.csSelections
    csScores: $parts.ForeachCorpus0.output.csScores

    caScores: $parts.ForeachCorpus0.output.caScores
  }

  # small|real
  variant: $MMTBaseline.Experiment.variant

  corpus_data: $MMT_CORPUS_DIR + "/" + $variant

  corpora_truecased_train: [ $corpus_data + "/" + $trainCorpora[$i] + "/train.clean." | i: [0..$trainCorpora.length-1] ]

  corpus_truecased_dev: $corpus_data + "/" + $corpora.dev + "/set1.clean."
  corpus_truecased_test: $corpus_data + "/" + $corpora.test + "/set2.clean."

  # #lines used for C_in, the in-domain corpus used to select "hidden" training data in the retrieval task.
  #nlines_C_in: 20000
  nlines_C_in: 2000 # TODO testing only
  # #lines used for C_hide, the in-domain corpus "hidden" in the training data
  nlines_C_hide: 2000 # TODO testing only
  # NOTE: should this be const for all corpora? (nb. different sizes...)

  # hybrid language word rank threshold (10000?)
  rankThreshold: 1000

  # index of corpus to hide (essentially a C_in index)
  hideIndex: 0

  parts: {
    # POS tag all trainCorpora source sides
    PosTaggers0: {
      input: {
        trainSources: $_._.input.trainSources
        trainTargets: $_._.input.trainTargets
      }
      output: { corporaPos: [ $parts[$i].output.corpusPos ] }
      i: [0..$input.trainSources.length-1]
      parts: [{
        extends: $Bricks.Corpus.POS.PosTagger
        input: { corpus: $_._.input.trainSources[$i] }
        language: $sourceLang
      }]
    }

    # we run one selection experiment per corpus, each with their own C_in.

    ProcessCorpora0: {
      input: {
        trainSources: $_._.input.trainSources
        trainTargets: $_._.input.trainTargets
      }
      output: {
        corporaCinSrcPos: [ $parts[$i].output.cinSrcPos ]
        corporaChideSrcPos: [ $parts[$i].output.chideSrcPos ]
        corporaCinAlignment: [ $parts[$i].output.cinAlignment ]
        corporaChideAlignment: [ $parts[$i].output.chideAlignment ]

        corporaCinTrg: [ $parts[$i].output.cinTrg ]
        corporaChideTrg: [ $parts[$i].output.chideTrg ]
        corporaChideSrc: [ $parts[$i].output.chideSrc ]

        corporaSrcPos: [ $parts[$i].output.srcPos ]
      }
      i: [0..$input.trainSources.length-1]
      parts: [{
        input: {
          src: $_._.input.trainSources[$i]
          trg: $_._.input.trainTargets[$i]
        }
        output: {
          cinSrcPos: $parts.SplitSrcPosLines0.output.texts[0]
          chideSrcPos: $parts.SplitSrcPosLines0.output.texts[1]

          cinAlignment: $parts.SplitAlignmentLines0.output.texts[0]
          chideAlignment: $parts.SplitAlignmentLines0.output.texts[1]

          cinTrg: $parts.SplitTrgLines0.output.texts[0]
          chideTrg: $parts.SplitTrgLines0.output.texts[1]
          chideSrc: $parts.SplitSrcLines0.output.texts[1]

          srcPos: $parts.PosTaggerSrc0.output.corpusPos
        }

        # deterministic random seed (each Shuffle produces same ordering)
        corpusRandomSeed: 42

        parts: {
          WordAligner0: {
            extends: $Bricks.Giza.WordAligner
            input: {
              src: $_._.input.src
              trg: $_._.input.trg
            }
            # output: { alignment }
            cacheDir: $WORD_ALIGNMENT_CACHE_DIR
          }

          PosTaggerSrc0: {
            extends: $Bricks.Corpus.POS.PosTagger
            input: { corpus: $_._.input.src }
            # output: { corpusPos }
            language: $sourceLang
          }

          ShuffleSrcPos0: {
            extends: $Bricks.Corpus.Shuffle
            input:  { textFile: $PosTaggerSrc0.output.corpusPos }
            # output: { head }

            seed: $corpusRandomSeed
          }
          ShuffleAlignment0: {
            extends: $Bricks.Corpus.Shuffle
            input:  { textFile: $WordAligner0.output.alignment }
            # output: { head }

            seed: $corpusRandomSeed
          }
          ShuffleTrg0: {
            extends: $Bricks.Corpus.Shuffle
            input:  { textFile: $_._.input.trg }
            # output: { head }

            seed: $corpusRandomSeed
          }
          ShuffleSrc0: {
            extends: $Bricks.Corpus.Shuffle
            input:  { textFile: $_._.input.src }
            # output: { head }

            seed: $corpusRandomSeed
          }

          # can't use?? why? output wiring complexity.
          #
          #ShuffleCorpora0: {
          #  extends: $Bricks.Corpus.ShuffleCorpora
          #  input: { textFiles: [
          #    $PosTaggerSrc0.output.corpusPos
          #    $WordAligner0.output.alignment
          #  ] }
          #  # output: { shuffledFiles: [] }
          #}

          # split into C_in and C_hide (hidden part)
          SplitSrcPosLines0: {
            extends: $Bricks.Corpus.SplitLines
            input: { text: $ShuffleSrcPos0.output.head }
            # output: { texts: [] }
            nlines: [ $nlines_C_in, END ]
          }
          SplitAlignmentLines0: {
            extends: $Bricks.Corpus.SplitLines
            input: { text: $ShuffleAlignment0.output.head }
            # output: { texts: [] }
            nlines: [ $nlines_C_in, END ]
          }
          SplitTrgLines0: {
            extends: $Bricks.Corpus.SplitLines
            input: { text: $ShuffleTrg0.output.head }
            # output: { texts: [] }
            nlines: [ $nlines_C_in, END ]
          }
          # TODO: list style agnostic processing, such as far below. Shuffle, Split.

          SplitSrcLines0: {
            extends: $Bricks.Corpus.SplitLines
            input: { text: $ShuffleSrc0.output.head }
            # output: { texts: [] }
            nlines: [ $nlines_C_in, END ]
          }
        }
      }]
    }

    # concatenate for vocabulary
    ConcatSrc0: {
      extends: $Bricks.Corpus.Concat
      input: { texts: $_._.input.trainSources }
      # output: { concat }
    }

    # global vocabulary to ensure identical word ranks
    GetVocabulary0: {
      extends: $GetVocabulary
      input: { corpus: $ConcatSrc0.output.concat }
      # output: { vocabulary }
    }

    # concatenate all corpora for general-domain selection LM
    ConcatSrcPos0: {
      extends: $Bricks.Corpus.Concat
      input: { texts: $ProcessCorpora0.output.corporaSrcPos }
      # output: { concat }
    }

    # general-domain selection LM
    GeneralLM0: {
      extends: $SelectionLM
      input:  { corpusPos: $ConcatSrcPos0.output.concat, vocabulary: $GetVocabulary0.output.vocabulary }
      # output: { languageModelHybrid }
    }

    # run the selection experiment for each corpus.
    # i.e. every iteration, C_in is a different corpus, different C_mix, ...
    #
    ForeachCorpus0: {
      input: {
        fileList: [
          $ProcessCorpora0.output.corporaChideSrcPos
          $ProcessCorpora0.output.corporaChideTrg
          $ProcessCorpora0.output.corporaChideAlignment
        ]
        generalLM: $GeneralLM0.output.languageModelHybrid
        corporaCinSrcPos: $ProcessCorpora0.output.corporaCinSrcPos
        corporaCinTrg: $ProcessCorpora0.output.corporaCinTrg
        vocabulary: $GetVocabulary0.output.vocabulary
        corporaChideSrc: $ProcessCorpora0.output.corporaChideSrc
      }
      output: {
        mlSelections: [ $parts[$i].output.mlSelection ]
        mlScores: [ $parts[$i].output.mlScore ]

        csSelections: [ $parts[$i].output.csSelection ]
        csScores: [ $parts[$i].output.csScore ]

        caScores: [ $parts[$i].output.caScore ]
      }

      # outer $i
      i: [0..$trainCorpora.length-1]

      parts: [{
        input: {
          fileList: $_._.input.fileList
          generalLM: $_._.input.generalLM
          corpusCinSrcPos: $_._.input.corporaCinSrcPos[$i]
          corpusCinTrg: $_._.input.corporaCinTrg[$i]
          vocabulary: $_._.input.vocabulary

          corporaChideSrc: $_._.input.corporaChideSrc
        }
        output: {
          mlSelection: $parts.HybridMooreLewis0.output.selection
          mlScore: $parts.EvaluateMooreLewisSelection0.output.score

          csSelection: $parts.CuongSimaan0.output.selection
          csScore: $parts.EvaluateCuongSimaanSelection0.output.score

          caScore: $parts.ContextAnalyzer09.output.score
        }

        # outer $i
        hideIndex: $i

        parts: {
          # NOTE: XXX: this is now defined twice :(
          #
          # create C_mix by hiding a specific amount of C_hide in a mixture of
          # other corpora.
          MixSelectionList0: {
            input: { fileList: $_._.input.fileList }
            output: {
              files_C_mix: [ $parts[$i].output.concat_C_mix ]
              files_C_out: [ $parts[$i].output.concat_C_out ]
            }

            # inner $i
            i: [0..$input.fileList.length-1]

            parts: [{
              input: { textFiles: $_._.input.fileList[$i] }
              output: {
                concat_C_mix: $parts.ConcatAddChide0.output.concat
                concat_C_out: $parts.ConcatExcept0.output.concat
              }

              parts: {
                # concat everything except for C_hide
                ConcatExcept0: {
                  extends: $Bricks.Corpus.ConcatExcept
                  input:  { texts: $_._.input.textFiles }
                  # output: { concat }

                  exceptIndex: $hideIndex
                }

                # note: C_hide is always at the beginning!
                ConcatAddChide0: {
                  extends: $Bricks.Corpus.Concat
                  input: { texts: [ $Limiter0.output.head, $ConcatExcept0.output.concat ] }
                  # output: { concat }
                }

                # get specific amount of C_hide
                Limiter0: {
                  extends: $Bricks.Corpus.Head
                  input: { textFile: $_._.input.textFiles[$hideIndex] }
                  # output: { head }

                  nlines: $nlines_C_hide
                }
              }
            }]
          }

          # just provide sane naming again
          MixSelection0: {
            input: { selectionFiles: $MixSelectionList0.output.files_C_mix }
            output: { cmixSrcPos, cmixTrg, cmixAlignment }
            template: """
              ln -sf ../input/selectionFiles/0 output/cmixSrcPos
              ln -sf ../input/selectionFiles/1 output/cmixTrg
              ln -sf ../input/selectionFiles/2 output/cmixAlignment
            """
          }
          # just provide sane naming again
          OutDomain0: {
            input: { selectionFiles: $MixSelectionList0.output.files_C_out }
            output: { coutSrcPos, coutTrg, coutAlignment }
            template: """
              ln -sf ../input/selectionFiles/0 output/coutSrcPos
              ln -sf ../input/selectionFiles/1 output/coutTrg
              ln -sf ../input/selectionFiles/2 output/coutAlignment
            """
          }

          # Build LM from C_in
          CinLM0: {
            extends: $SelectionLM
            input:  { corpusPos: $_._.input.corpusCinSrcPos, vocabulary: $_._.input.vocabulary }
            # output: { languageModelHybrid }
          }

          # Build LM from C_out
          CoutLM0: {
            extends: $SelectionLM
            input:  { corpusPos: $OutDomain0.output.coutSrcPos, vocabulary: $_._.input.vocabulary }
            # output: { languageModelHybrid }
          }

          HybridMooreLewis0: {
            input: {
              #generalLM: $_._.input.generalLM
              generalLM: $CoutLM0.output.languageModelHybrid
              cinLM: $CinLM0.output.languageModelHybrid
              cmix: $MixSelection0.output.cmixSrcPos
              vocabulary: $_._.input.vocabulary
            }
            output: {
              # 1-based line permutation index file
              selection: $parts.MooreLewisRanking0.output.selection
            }

            parts: {
              ScoreGeneral0: {
                extends: $ScorePosLines
                input:  {
                  textPos: $_._.input.cmix
                  languageModelHybrid: $_._.input.generalLM
                  vocabulary: $_._.input.vocabulary
                }
                # output: { score }
              }
              ScoreCin0: {
                extends: $ScorePosLines
                input:  {
                  textPos: $_._.input.cmix
                  languageModelHybrid: $_._.input.cinLM
                  vocabulary: $_._.input.vocabulary
                }
                # output: { score }
              }
              MooreLewisRanking0: {
                extends: $MooreLewisRanking
                input: { scoreGeneral: $ScoreGeneral0.output.score, scoreCin: $ScoreCin0.output.score }
                # output: { selection }
              }
            }
          }

          EvaluateMooreLewisSelection0: {
            extends: $EvaluateSelection
            input: { selection: $HybridMooreLewis0.output.selection }
            # output: { score }

            nsel: $nlines_C_in
          }


          # get surface word form from factored format
          Surface0: {
            input: {
              cinSrcPos: $_._.input.corpusCinSrcPos
              cmixSrcPos: $MixSelection0.output.cmixSrcPos
            }
            output: { cinSrc, cmixSrc }
            template: """
              # get surface word form from factored format
              # (note: template string notation must double-escape backslashes)
              function surface() { sed 's/\\([^ ]\\+\\)|[^ ]\\+/\\1/g'; }
              surface < input/cinSrcPos > output/cinSrc
              surface < input/cmixSrcPos > output/cmixSrc
            """
          }

          CuongSimaan0: {
            extends: $CuongSimaan
            input: {
              cinSrc: $Surface0.output.cinSrc
              cmixSrc: $Surface0.output.cmixSrc

              cinTrg: $_._.input.corpusCinTrg
              cmixTrg: $MixSelection0.output.cmixTrg
            }
            # output: { selection }
          }

          EvaluateCuongSimaanSelection0: {
            extends: $EvaluateSelection
            input: { selection: $CuongSimaan0.output.selection }
            # output: { score }

            nsel: $nlines_C_in
          }

          # general data-selection interface:
          # <nlines-select>
          # creates a 1-based line permutation index file with the first
          # nlines-select lines being
          # the selected data, and the rest below (intuitive: like sort output).
          #
          # easy to evaluate, since the first $nlines_C_in lines of C_mix
          # are always C_in.


          # MMT ContextAnalyzer v0.9
          ContextAnalyzer09: {
            extends: $ContextAnalyzer_v09_Brick
            input: {
              cinSrc: $Surface0.output.cinSrc
              domainCorporaSrc: $MultiLimiter0.output.textFiles
            }
            # output: { score }

            # 0-based index of active domain (to return score for)
            domainId: $hideIndex
          }

          # get domains from $ProcessCorpora0.output....
          # but: need to limit the in-dom since that's what we did everywhere

          # get C_mix corpus parts, with specific amount of C_hide
          #
          # NOTE: XXX: this is now defined twice :(
          #
          MultiLimiter0: {
            input: { textFiles: $_._.input.corporaChideSrc }
            output: { textFiles }

            limitIndex: $hideIndex
            nlinesLimit: $nlines_C_hide

            template: """
              mkdir -p output/textFiles

              {% for textFile in brick.input.textFiles -%}
                {% if loop.index0 == brick.limitIndex -%}
                  head -n {{ brick.nlinesLimit }} input/textFiles/{{ loop.index0 }} > output/textFiles/{{ loop.index0 }}
                {% else -%}
                  ln -sf ../../input/textFiles/{{ loop.index0 }} output/textFiles/{{ loop.index0 }}
                {% endif %}
              {% endfor %}
            """
          }


          # obtain actual parallel corpora + word alignment from the selection.

          MultiCorpusSel0: {
            extends: $MultiCorpusSel
            input: {
              cmixSrc: $Surface0.output.cmixSrc
              cmixTrg: $MixSelection0.output.cmixTrg
              cmixAlignment: $MixSelection0.output.cmixAlignment
              selections: [
                $HybridMooreLewis0.output.selection
                $CuongSimaan0.output.selection
                # CA currently doesn't output a 'selection', so no BLEU eval there.
              ]
            }
            # output: { sources: [], targets: [], alignments: [] }
          }
        }
      }]
    }
  }
}



Hybridize: {
  input: { corpusPos, vocabulary }
  output: { corpusHybrid }

  # hybrid language word rank threshold
  rankThreshold

  # from Experiment
  bricksDir: $BRICKS

  template: """
    {{ brick.bricksDir }}/scripts/data_selection/hybridize.py -t {{ brick.rankThreshold }} \\
      input/vocabulary < input/corpusPos > output/corpusHybrid
  """
}

GetVocabulary: {
  input: { corpus }
  output: { vocabulary }

  # from Experiment
  bricksDir: $BRICKS

  template: """
    {{ brick.bricksDir }}/scripts/data_selection/get_vocabulary.py < input/corpus > output/vocabulary
  """
}


SelectionLM: {
  input:  { corpusPos, vocabulary }
  # languageModel: binarized KenLM
  output: { languageModelHybrid: $parts.LM0.output.languageModel }

  # hybrid language word rank threshold
  # from Experiment
  rankThreshold: $_.rankThreshold

  parts: {
    Hybridize0: {
      extends: $Hybridize

      input: { corpusPos: $_._.input.corpusPos, vocabulary: $_._.input.vocabulary }
      # output: { corpusHybrid }

      # from SelectionLM
      rankThreshold: $_.rankThreshold
    }

    LM0: {
      extends: $Bricks.LM.LanguageModelEstimator
      input:  { corpus: $Hybridize0.output.corpusHybrid }
      # output: { languageModel }

      ngramOrder: 4
      prune: "0 0 1"
      extraOptions: "--discount_fallback"
    }
  }
}

# Hybridize POS-tagged text before scoring it.
#
ScorePosLines: {
  input:  { textPos, languageModelHybrid, vocabulary }
  output: { score: $parts.Score0.output.score }

  # hybrid language word rank threshold
  # from Experiment
  rankThreshold: $_.rankThreshold

  parts: {
    Hybridize0: {
      extends: $Hybridize

      input: { corpusPos: $_._.input.textPos, vocabulary: $_._.input.vocabulary }
      # output: { corpusHybrid }

      # from ScoreLines
      rankThreshold: $_.rankThreshold
    }

    Score0: {
      extends: $Bricks.LM.ScoreLines
      input:  { text: $Hybridize0.output.corpusHybrid, languageModel: $_._.input.languageModelHybrid }
      # output: { score }
    }
  }
}

MooreLewisRanking: {
  input: { scoreGeneral }
  output: { selection }
  template: """
    # compute cross-entropy difference H_in(s) - H_gen(s), add line number
    paste input/scoreCin input/scoreGeneral | awk '{print ($1 - $2) "\t" NR}' > output/xe-diff
    # float-numeric, descending sort
    sort -g -r output/xe-diff > output/xe-diff.ranked
    awk '{print $2}' output/xe-diff.ranked > output/xe-rank
    ln -sf xe-rank output/selection
    # clean up
    #rm -rf output/xe-diff.ranked output/xe-diff
    # nicer debugging
    rm -rf output/xe-diff
  """
}

EvaluateSelection: {
  input: { selection }
  output: { score }

  # from Experiment
  bricksDir: $BRICKS

  # number of sentences that have been selected (should be same as hidden C_in size)
  nsel

  template: """
    {{ brick.bricksDir }}/scripts/data_selection/eval.py \\
      --nsel {{ brick.nsel }} --nin {{ brick.nsel }} \\
      < input/selection > output/score
  """
}


CuongSimaan: {
  input: {
    cinSrc: $Surface0.output.cinSrc
    cmixSrc: $Surface0.output.cmixSrc

    cinTrg: $_._.input.corpusCinTrg
    cmixTrg: $MixSelection0.output.cmixTrg
  }
  output: { selection }

  # from Experiment
  sourceLang: $_.sourceLang
  targetLang: $_.targetLang

  # from Experiment
  tools: $POS_TOOLS_DIR
  java: $JAVA_HOME

  # number of EM iterations for the used IBM Model 1
  niterations: 1

  # NOTE: as far as I remember, the EM does not converge to the proper corpus
  # parts, and hence, one iteration is the best we could do. YMMV.

  template: """
    # lang pair has no effect, is really just for being nice
    src={{ brick.sourceLang }}
    trg={{ brick.targetLang }}

    # set up corpus.fr, corpus.it suffix files (temp files written there... -> output/)
    ln -sf ../input/cinSrc output/cin.$src
    ln -sf ../input/cinTrg output/cin.$trg
    ln -sf ../input/cmixSrc output/cmix.$src
    ln -sf ../input/cmixTrg output/cmix.$trg

    # clean up from last run
    rm -rf output/output_*

    # InvitationModel writes temp and output files in wd, so change to convenient place
    cd output
    {{ brick.java }}/bin/java -cp {{ brick.tools }}/InvitationModel/target/invitationmodel-1.0.jar \\
      nl.uva.illc.dataselection.InvitationModel -cin cin -cmix cmix -src $src -trg $trg \\
      -i {{ brick.niterations }}
    # get output from last iteration
    awk '{print $1}' output_{{ brick.niterations }}.txt > selection
    # clean up the remaining temp stuff in the directory...
    rm -rf *.encoded *.lm outdomain.scores
    # leaving these iteration files for debug only:
    # rm -rf output_*.txt
    gzip output_*.txt
    cd ..
  """
}


# MMT ContextAnalyzer v0.9
ContextAnalyzer_v09_Brick: {
  input: {
    cinSrc
    domainCorporaSrc: []
  }
  output: { score }

  # from Experiment
  sourceLang: $_.sourceLang

  # from Experiment
  tools: $POS_TOOLS_DIR
  java: $JAVA_HOME

  # 0-based index of active domain (to return score for)
  domainId



  template: """
    JAVA_HOME={{ brick.java }}
    TOOLS={{ brick.tools }}
    CLASSPATH=$TOOLS/context-analyzer/0.9/context-analyzer.jar
    src={{ brick.sourceLang }}
    data=output/corpus-data
    index=output/index

    mkdir -p $data $index

    # copy and name all subcorpus files (+ replace workaround)
    for f in input/domainCorporaSrc/*; do
      bn=$(basename $f)
      # naming subcorpora: subc-${bn}
      sed 's/&/AMPERSAND/g' $f > $data/subc-${bn}.${src}
    done

    # build Lucene index
    $JAVA_HOME/bin/java -cp $CLASSPATH net.translated.contextanalyzer.cli.CreateIndex \\
      -i $(pwd)/$index -c $(pwd)/$data

    # TODO: fix dependency on jsvc
    # start up the server (launches a background daemon by itself)
    $(which jsvc) -home $JAVA_HOME -cp $CLASSPATH -user $(whoami) -outfile $(pwd)/output/ca.out \\
      -errfile $(pwd)/output/ca.err -pidfile $(pwd)/output/ca.pid net.translated.contextanalyzer.http.Server \\
      -p 7532 -i $(pwd)/$index

    # wait for startup
    sleep 1

    trap "{ kill $(cat output/ca.pid); }" EXIT

    python -c 'if __name__ == "__main__":
      import requests, sys, json

      cinSrc = sys.stdin.read().replace("&", "AMPERSAND").replace("\\n", "  ")
      r = requests.get("http://localhost:7532/context", params={"of": "json", "language": "{{ brick.sourceLang }}", "context": cinSrc})
      # why no r.text: old requests on cluster :(
      d = r.raw.data if type(r.raw.data) is str else r.text
      domainScores = json.loads(d)
      # may need to normalize scores for later CA versions

      print(domainScores["subc-{{ brick.domainId }}"])

      # write debug stuff
      with open("output/reply.json", "w") as fo:
        fo.write(d)

    ' < input/cinSrc > output/score

    # kill the server
    kill $(cat output/ca.pid)
  """
}

# Given 1-based line indices in 'selection', provide the selected part
# of an aligned parallel corpus.
#
CorpusSelector: {
  input: { cmixSrc, cmixTrg, cmixAlignment, selection }
  output: { src, trg, alignment }

  # from Experiment
  bricksDir: $BRICKS

  template: """
    function permute() {
      {{ brick.bricksDir }}/scripts/data_selection/permute.py input/selection fwd
    }

    permute < input/cmixSrc > output/src
    permute < input/cmixTrg > output/trg
    permute < input/cmixAlignment > output/alignment
  """
}

MultiCorpusSel: {
  input: { cmixSrc, cmixTrg, cmixAlignment, selections: [] }
  output: {
    sources: [ $parts[$i].output.src ]
    targets: [ $parts[$i].output.trg ]
    alignments: [ $parts[$i].output.alignment ]
  }

  i: [0..$input.selections.length-1]

  parts: [{
    extends: $CorpusSelector
    input: {
      cmixSrc: $_._.input.cmixSrc
      cmixTrg: $_._.input.cmixTrg
      cmixAlignment: $_._.input.cmixAlignment
      selection: $_._.input.selections[$i]
    }
    # output: { src, trg, alignment }
  }]
}

Bricks: @<Bricks.cfg>

# overridden in $Setup / Hopper.cfg only, to simplify testing experiments
MMT_VARIANT: $Setup.MMT_VARIANTS.real

MMTBaseline: @"baseline.cfg"

SinglePruningExperiment: {
  extends: $MMTBaseline.Experiment

  DESCRIPTION: """
    Count-based pruning.

    Moses with cube pruning decoder.

  """ + $corporaDescription

  # output: {
  #   hyp: $parts.TestMoses0.output.hyp
  #   score: $parts.Bleu0.output.score
  #   summary: $parts.Summary0.output.summary
  # }

  parts: {
    extends: $MMTBaseline.Experiment.parts

    # override
    PhraseTable0: {
      extends: $MMTBaseline.Experiment.parts.PhraseTable0

      # from SinglePruningExperiment
      minCount: $_.countPruningThreshold
    }
  }

  # joint count N(f,e) threshold - drop phrase pairs occurring less often
  countPruningThreshold: 0
}

Experiment: {
  extends: $MMTBaseline.Experiment  # for $corpus_truecased_train etc ...

  DESCRIPTION: """
    Sweep through various count-based pruning thresholds.

    Moses with cube pruning decoder.

  """ + $corporaDescription

  output: {
    report: $parts.Aggregate0.output.report
  }

  # note: bash-based experiment markup could avoid this weird passing through
  # by using automatic ../ prefixing of paths

  # (but we could also "just" support lazy wiring of bricks to grandparents)
  # (do parents get the inputs automatically? ...)

  # joint count N(f,e) threshold - drop phrase pairs occurring less often
  countPruningThresholds: [ 0, 1, 2, 5, 10, 20 ]

  # this is for the initial tuning run only.
  countPruningThreshold: 0

  parts: {
    # inherit some parts...
    extends: $SinglePruningExperiment.parts

    # ... and define some more.

    MinCountSweep0: {
      input:  {
        src: $LimitTrain0.output.src
        trg: $LimitTrain0.output.trg

        languageModel: $LanguageModel0.output.languageModel
        alignment: $WordAligner0.output.alignment

        devSrc: $_._.input.devSrc
        devRef: $_._.input.devRef

        testSrc: $_._.input.testSrc
        testRef: $_._.input.testRef

        initialTunedMosesIni: $Mert0.output.tunedMosesIni
      }
      output: {
        # hyps: [ $parts[$i].output.hyp ]
        scores: [ $parts[$i].output.score ]
      }

      # magic loop config pattern (detected by parts: [{}] syntax)
      i: [0..$countPruningThresholds.length-1]

      parts: [{
        # implicit scalar $i

        extends: $SinglePruningExperiment
        input:  {
          src: $_._.input.src
          trg: $_._.input.trg

          languageModel: $_._.input.languageModel
          alignment: $_._.input.alignment

          devSrc: $_._.input.devSrc
          devRef: $_._.input.devRef

          testSrc: $_._.input.testSrc
          testRef: $_._.input.testRef

          initialTunedMosesIni: $_._.input.initialTunedMosesIni
        }

        countPruningThreshold: $countPruningThresholds[$i]

        parts: {
          extends: $SinglePruningExperiment.parts

          # we don't need to repeat some things over and over... reuse.

          # overrides $MMTBaseline.Experiment.parts.LimitTrain0
          LimitTrain0: {
            input:  {
              src: $_._.input.src
              trg: $_._.input.trg
            }
            output: { src, trg }

            template: """
              ln -sf ../input/src output/src
              ln -sf ../input/trg output/trg
            """
          }

          # overrides $MMTBaseline.Experiment.parts.LanguageModel0
          LanguageModel0: {
            input:  { languageModel: $_._.input.languageModel }
            output: { languageModel }
            template: """
              ln -sf ../input/languageModel output/languageModel
            """
          }

          # overrides $MMTBaseline.Experiment.parts.WordAligner0
          WordAligner0: {
            input:  { alignment: $_._.input.alignment }
            output: { alignment }
            template: """
              ln -sf ../input/alignment output/alignment
            """
          }

          # TODO: do we really need to re-tune each version?
          # (this experiment would be quicker using sampling phrasetables)

          # provide initial weights to dev moses.ini so MERT will
          # converge faster.
          # TODO: --use-config-weights-for-first-run in Mert
          #
          DevWeightedMosesIni0: {
            extends: $Bricks.Moses.WeightedMosesIni
            input: {
              generatedMosesIni: $PrunedPTDevMosesIni0.output.mosesIni
              tunedMosesIni: $_._.input.initialTunedMosesIni
            }
            # output: { weightedMosesIni }
          }

          # (need this to rename output...)
          # overrides $MMTBaseline.Experiment.parts.DevMosesIni0
          DevMosesIni0: {
            input:  { mosesIni: $DevWeightedMosesIni0.output.weightedMosesIni }
            output: { mosesIni }
            template: """
              ln -sf ../input/mosesIni output/mosesIni
            """
          }

          PrunedPTDevMosesIni0: {
            extends: $Bricks.Moses.MosesIni
            input: {
              languageModels: [ $LanguageModel0.output.languageModel ]
              phraseTables: []
              reorderingTables: []
              binaryPhraseTables: [ $DevTables0.output.binaryPhraseTableDir ]
              binaryReorderingTables: [ $DevTables0.output.binaryReorderingTableDir ]
            }
            # output: { mosesIni }
          }
        }
      }]
    }

    Aggregate0: {
      input:  { scores: $MinCountSweep0.output.scores }
      output: { report }

      # from Experiment
      countPruningThresholds: $_.countPruningThresholds

      template: """
        rm -f output/report
        {% for minCount in brick.countPruningThresholds -%}
          echo -n "{{ minCount }} " >> output/report
          gawk -F ' |,' '{print $3}' input/scores/{{ loop.index0 }} >> output/report
        {% endfor %}
      """
    }
  }
}
